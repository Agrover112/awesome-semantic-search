# Impressionnant Recherche-SÃ©mantique [![Impressionnant](https://awesome.re/badge.svg)](https://awesome.re) [![Commits Conventionnels](https://img.shields.io/badge/Commits%20Conventionnels-1.0.0-jaune.svg)](https://conventionalcommits.org)

<img src ="logo.svg" />

Logo rÃ©alisÃ© par [@createdbytango](https://instagram.com/createdbytango).

**Ã€ la recherche d'ajouts de papiers supplÃ©mentaires.
PS : Soumettez une Pull Request**

Le rÃ©fÃ©rentiel suivant vise Ã  servir de mÃ©ta-rÃ©fÃ©rentiel pour les tÃ¢ches liÃ©es Ã  la [recherche sÃ©mantique](https://en.wikipedia.org/wiki/Semantic_search) et Ã  la [similaritÃ© sÃ©mantique](http://nlpprogress.com/english/semantic_textual_similarity.html).

La recherche sÃ©mantique n'est pas limitÃ©e au texte ! Elle peut Ãªtre rÃ©alisÃ©e avec des images, de la parole, etc. Il existe de nombreux cas d'utilisation et applications diffÃ©rents de la recherche sÃ©mantique.

N'hÃ©sitez pas Ã  soumettre une [Pull Request](https://github.com/Agrover112/awesome-semantic-search/projects/1) sur ce rÃ©fÃ©rentiel !

## Contenu

- [Papiers](#papers)
    - [2014](#2014)
    - [2015](#2015)
    - [2016](#2016)
    - [2017](#2017)
    - [2018](#2018)
    - [2019](#2019)
    - [2020](#2020)
    - [2021](#2021)
    - [2022](#2022)
    - [2023](#2023)
- [Articles](#articles)
- [BibliothÃ¨ques et Outils](#libraries-and-tools)
- [Ensembles de donnÃ©es](#datasets)
- [Ã‰tapes Importantes](#milestones)

## Papiers

### 2010
- [Priority Range Trees](https://arxiv.org/abs/1009.3527)

### 2014 
- [Un ModÃ¨le SÃ©mantique Latent avec une Structure de Convolutions-Pooling pour la RÃ©cupÃ©ration d'Informations](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2014_cdssm_final.pdf) ğŸ“„

### 2015
- [Vecteurs Skip-Thought](https://arxiv.org/pdf/1506.06726.pdf) ğŸ“„
- [LSH Pratique et Optimal pour la Distance Angulaire](https://proceedings.neurips.cc/paper/2015/hash/2823f4797102ce1a1aec05359cc16dd9-Abstract.html)

### 2016
- [Sac de Trucs pour la Classification Efficace du Texte](https://arxiv.org/abs/1607.01759) ğŸ“„
- [Enrichissement des Vecteurs de Mots avec des Informations Subword](https://arxiv.org/abs/1607.04606) ğŸ“„
- [Recherche de Voisin le Plus Proche Approximatif Efficace et Robuste en Utilisant des Graphes Mondiaux Navigables HiÃ©rarchiques](https://arxiv.org/abs/1603.09320)
- [Recherche Approximative du Voisin le Plus Proche pour les Vecteurs de Mots Similaires - ExpÃ©riences, Analyses et AmÃ©lioration](https://www.aclweb.org/anthology/P16-1214.pdf) 
- [Apprentissage de ReprÃ©sentations DistribuÃ©es de Phrases Ã  Partir de DonnÃ©es Non Ã‰tiquetÃ©es](https://arxiv.org/abs/1602.03483) ğŸ“„
- [Recherche Approximative du Voisin le Plus Proche sur des DonnÃ©es de Grande Dimension --- ExpÃ©riences, Analyses et AmÃ©lioration](https://arxiv.org/abs/1610.02455)

### 2017
- [Apprentissage SupervisÃ© de ReprÃ©sentations Universelles de Phrases Ã  Partir de DonnÃ©es d'InfÃ©rence en Langage Naturel](https://research.fb.com/wp-content/uploads/2017/09/emnlp2017.pdf) ğŸ“„
- [SimilaritÃ© Textuelle SÃ©mantique pour le Hindi](https://www.semanticscholar.org/paper/Semantic-Textual-Similarity-For-Hindi-Mujadia-Mamidi/372f615ce36d7543512b8e40d6de51d17f316e0b) ğŸ“„
- [Suggestion Efficace de RÃ©ponses en Langage Naturel pour Smart Reply](https://arxiv.org/abs/1705.00652) ğŸ“ƒ

### 2018
- [Encodeur Universel de Phrases](https://arxiv.org/pdf/1803.11175.pdf) ğŸ“„
- [Apprentissage de la SimilaritÃ© Textuelle SÃ©mantique Ã  Partir de Conversations](https://arxiv.org/pdf/1804.07754.pdf) ğŸ“„
- [Blog Google AI : AvancÃ©es dans la SimilaritÃ© Textuelle SÃ©mantique](https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html) ğŸ“„
- [Speech2Vec : Un Cadre SÃ©quence Ã  SÃ©quence pour Apprendre des Embarquements de Mots Ã  Partir de la Parole](https://arxiv.org/abs/1803.08976)) ğŸ”Š
- [Optimisation de l'Indexation BasÃ©e sur le Graphique du Voisin le Plus Proche k pour la Recherche de ProximitÃ© dans des DonnÃ©es de Grande Dimension](https://arxiv.org/abs/1810.07355) ğŸ”Š
- [Recherche Efficace du Voisin le Plus Proche Approximatif avec le Graphique de DissÃ©mination](http://www.vldb.org/pvldb/vol12/p461-fu.pdf)
- [Plaidoyer pour des Structures d'Indexation Apprises](https://dl.acm.org/doi/10.1145/3183713.3196909)

### 2019
- [LASER : ReprÃ©sentations de phrases indÃ©pendantes du langage](https://engineering.fb.com/2019/01/22/ai-research/laser-multilingual-sentence-embeddings/) ğŸ“„
- [Expansion de document par prÃ©diction de requÃªte](https://arxiv.org/abs/1904.08375) ğŸ“„
- [Sentence-BERT : IntÃ©gration de phrases Ã  l'aide de rÃ©seaux Siamese BERT](https://arxiv.org/pdf/1908.10084.pdf) ğŸ“„
- [Classement de documents Ã  plusieurs Ã©tapes avec BERT](https://arxiv.org/abs/1910.14424) ğŸ“„
- [RÃ©cupÃ©ration latente pour le questionnement faiblement supervisÃ© en domaine ouvert](https://arxiv.org/abs/1906.00300)
- [Question-rÃ©ponse de bout en bout avec BERTserini](https://www.aclweb.org/anthology/N19-4013/)
- [BioBERT : un modÃ¨le de reprÃ©sentation linguistique biomÃ©dicale prÃ©-entraÃ®nÃ© pour l'extraction de texte biomÃ©dical](https://arxiv.org/abs/1901.08746)ğŸ“„
- [Analyse et amÃ©lioration des reprÃ©sentations avec la perte douce du voisin le plus proche](https://arxiv.org/pdf/1902.01889.pdf)ğŸ“·
- [DiskANN : Recherche rapide et prÃ©cise du voisin le plus proche pour un milliard de points sur un seul nÅ“ud](https://proceedings.neurips.cc/paper/2019/file/09853c7fb1d3f8ee67a61b6bf4a7f8e6-Paper.pdf)

### 2020
- [DÃ©ploiement rapide d'un moteur de recherche neuronal pour le COVID-19 Open Research Dataset : RÃ©flexions prÃ©liminaires et leÃ§ons apprises](https://arxiv.org/abs/2004.05125) ğŸ“„
- [RE-CLASSEMENT DE PASSAGE AVEC BERT](https://arxiv.org/pdf/1901.04085.pdf) ğŸ“„
- [CO-Search : Recherche d'informations sur le COVID-19 avec recherche sÃ©mantique, question-rÃ©ponse et rÃ©sumÃ© abstrait](https://arxiv.org/pdf/2006.09595.pdf) ğŸ“„
- [LaBSE : IntÃ©gration de phrases sans langage](https://arxiv.org/abs/2007.01852) ğŸ“„
- [Covidex : ModÃ¨les de classement neuronal et infrastructure de recherche par mot-clÃ© pour le COVID-19 Open Research Dataset](https://arxiv.org/abs/2007.07846) ğŸ“„
- [DeText : Un cadre d'IA profonde pour la comprÃ©hension intelligente du texte](https://engineering.linkedin.com/blog/2020/open-sourcing-detext) ğŸ“„
- [Rendre les plongements de phrases monolingues multilingues en utilisant la distillation des connaissances](https://arxiv.org/pdf/2004.09813.pdf) ğŸ“„
- [Transformateurs prÃ©-entraÃ®nÃ©s pour le classement de texte : BERT et au-delÃ ](https://arxiv.org/abs/2010.06467) ğŸ“„
- [REALM : PrÃ©-entraÃ®nement d'un modÃ¨le linguistique augmentÃ© par rÃ©cupÃ©ration](https://arxiv.org/abs/2002.08909)
- [ELECTRA : PRÃ‰-ENTRAÃNEMENT DES ENCODEURS DE TEXTE EN TANT QUE DISCRIMINATEURS PLUTÃ”T QUE DES GÃ‰NÃ‰RATEURS](https://openreview.net/pdf?id=r1xMH1BtvB)ğŸ“„
- [AmÃ©lioration de l'apprentissage profond pour la recherche Airbnb](https://arxiv.org/pdf/2002.05515)
- [Gestion de la diversitÃ© dans la recherche Airbnb](https://arxiv.org/abs/2004.02621)ğŸ“„
- [Apprentissage nÃ©gatif de contraste approximatif du voisin le plus proche pour la recherche dense de texte](https://arxiv.org/abs/2007.00808v1)ğŸ“„
- [Plongements d'images sans supervision pour les tÃ¢ches de recherche et de reconnaissance](https://openaccess.thecvf.com/content_WACV_2020/papers/Gairola_Unsupervised_Image_Style_Embeddings_for_Retrieval_and_Recognition_Tasks_WACV_2020_paper.pdf)ğŸ“·
- [DeCLUTR : Apprentissage en profondeur contrastif pour les reprÃ©sentations textuelles non supervisÃ©es](https://arxiv.org/abs/2006.03659)ğŸ“„


### 2021
- [Approche hybride pour le calcul de similaritÃ© sÃ©mantique entre les mots tamouls](https://www.researchgate.net/publication/350112163_Hybrid_approach_for_semantic_similarity_calculation_between_Tamil_words) ğŸ“„
- [SBERT augmentÃ©](https://arxiv.org/pdf/2010.08240.pdf) ğŸ“„
- [BEIR : un banc d'essai hÃ©tÃ©rogÃ¨ne pour l'Ã©valuation sans tir prÃ©alable des modÃ¨les de recherche d'informations](https://arxiv.org/abs/2104.08663) ğŸ“„
- [Recherche visuelle hÃ©tÃ©rogÃ¨ne compatible](https://arxiv.org/abs/2105.06047) ğŸ“·
- [Apprentissage du style personnel Ã  partir de quelques exemples](https://chuanenlin.com/personalstyle)ğŸ“·
- [TSDAE : Utilisation d'un auto-encodeur de dÃ©bruitage sÃ©quentiel basÃ© sur un transformateur pour l'apprentissage non supervisÃ© de l'intÃ©gration de phrases](https://arxiv.org/abs/2104.06979)ğŸ“„
- [Une enquÃªte sur les transformateurs](https://arxiv.org/abs/2106.04554)ğŸ“„ğŸ“·
- [SPLADE : ModÃ¨le lexical et d'expansion parcimonieux pour le classement de la premiÃ¨re Ã©tape](https://dl.acm.org/doi/10.1145/3404835.3463098)ğŸ“„
- [Suggestions de requÃªtes de recherche liÃ©es de haute qualitÃ© Ã  l'aide de l'apprentissage en profondeur par renforcement](https://arxiv.org/abs/2108.04452v1)
- [RÃ©cupÃ©ration de produits basÃ©e sur l'intÃ©gration dans la recherche Taobao](https://arxiv.org/pdf/2106.09297.pdf)ğŸ“„ğŸ“·
- [TPRM : Un modÃ¨le de classement personnalisÃ© basÃ© sur les sujets pour la recherche Web](https://arxiv.org/abs/2108.06014)ğŸ“„
- [mMARCO : Une version multilingue de l'ensemble de donnÃ©es de classement de passages MS MARCO](https://arxiv.org/abs/2108.13897)ğŸ“„
- [Raisonnement sur la base de donnÃ©es Ã  partir du texte](https://aclanthology.org/2021.acl-long.241.pdf)ğŸ“„
- [En quoi l'affinage adversarial profite-t-il Ã  BERT ?](https://arxiv.org/abs/2108.13602))ğŸ“„
- [EntraÃ®nement court, test long : l'attention avec des biais linÃ©aires permet l'extrapolation de la longueur d'entrÃ©e](https://arxiv.org/abs/2108.12409)ğŸ“„
- [Primer : Recherche d'architectures de transformateurs efficaces pour la modÃ©lisation linguistique](https://arxiv.org/abs/2109.08668)ğŸ“„
- [Ã€ quel point cela semble-t-il familier ? Analyse de similaritÃ© reprÃ©sentationnelle interlingue des plongements acoustiques de mots](https://arxiv.org/pdf/2109.10179.pdf)ğŸ”Š
- [SimCSE : Apprentissage contrastif simple des plongements de phrases](https://arxiv.org/abs/2104.08821#)ğŸ“„
- [Attention compositionnelle : DÃ©sentrelacement de la recherche et de la rÃ©cupÃ©ration](https://arxiv.org/abs/2110.09419)ğŸ“„ğŸ“·
- [SPANN : Recherche de voisin le plus proche efficace Ã  l'Ã©chelle du milliard](https://arxiv.org/abs/2111.08566)
- [GPL : Ã‰tiquetage pseudo-gÃ©nÃ©ratif pour l'adaptation de domaine non supervisÃ©e de la rÃ©cupÃ©ration dense](https://arxiv.org/abs/2112.07577) ğŸ“„
- [Moteurs de recherche gÃ©nÃ©ratifs : expÃ©riences initiales](https://computationalcreativity.net/iccc21/wp-content/uploads/2021/09/ICCC_2021_paper_50.pdf) ğŸ“·
- [Repenser la recherche : faire des experts de domaine Ã  partir de dilettantes](https://dl.acm.org/doi/10.1145/3476415.3476428)
- [WhiteningBERT : Une approche facile d'intÃ©gration de phrases non supervisÃ©e](https://arxiv.org/abs/2104.01767)

### 2022
- [IntÃ©gration de textes et de codes par prÃ©-entraÃ®nement contrastif](https://arxiv.org/abs/2201.10005)ğŸ“„
- [RELIC : RÃ©cupÃ©ration de preuves pour les revendications littÃ©raires](https://arxiv.org/abs/2203.10053)ğŸ“„
- [Trans-Encoder : ModÃ©lisation non supervisÃ©e de paires de phrases par auto-distillations mutuelles et mutuelles](https://arxiv.org/abs/2109.13059)ğŸ“„
- [SAMU-XLSR : ReprÃ©sentation multimodale de l'Ã©noncÃ© interlingue alignÃ©e sÃ©mantiquement](https://arxiv.org/abs/2205.08180)ğŸ”Š
- [Analyse des fonctions de fusion pour la recherche hybride](https://arxiv.org/abs/2210.11934)ğŸ“„
- [DÃ©tection hors distribution avec des voisins les plus proches profonds](https://arxiv.org/abs/2204.06507)
- [ESB : Un banc d'essai pour la reconnaissance de la parole de bout en bout multi-domaines](https://arxiv.org/abs/2210.13352)ğŸ”Š
- [Analyse des plongements acoustiques de mots Ã  partir de modÃ¨les de parole auto-supervisÃ©s prÃ©-entraÃ®nÃ©s](https://arxiv.org/pdf/2210.16043.pdf))ğŸ”Š
- [Repenser avec la rÃ©cupÃ©ration : InfÃ©rence fidÃ¨le de grands modÃ¨les linguistiques](https://arxiv.org/abs/2301.00303)ğŸ“„
- [RÃ©cupÃ©ration dense prÃ©cise sans Ã©tiquettes de pertinence](https://arxiv.org/pdf/2212.10496.pdf)ğŸ“„
- [MÃ©moire du transformateur en tant qu'index de recherche diffÃ©renciable](https://arxiv.org/abs/2202.06991)ğŸ“„

### 2023
- [FINGER : InfÃ©rence rapide pour la recherche du voisin le plus proche approximatif basÃ©e sur un graphe](https://dl.acm.org/doi/10.1145/3543507.3583318)ğŸ“„
- [Classification de texte "faible ressource" : une mÃ©thode de classification sans paramÃ¨tre avec des compresseurs](https://aclanthology.org/2023.findings-acl.426/)ğŸ“„
- [SparseEmbed : Apprentissage de reprÃ©sentations lexicales clairsemÃ©es avec des plongements contextuels pour la rÃ©cupÃ©ration](https://dl.acm.org/doi/pdf/10.1145/3539618.3592065) ğŸ“„

## Articles
- [Aborder la recherche sÃ©mantique](https://adityamalte.substack.com/p/tackle-semantic-search/)
- [Recherche sÃ©mantique dans Azure Cognitive Search](https://docs.microsoft.com/en-us/azure/search/semantic-search-overview)
- [Comment nous avons utilisÃ© la recherche sÃ©mantique pour rendre notre recherche 10 fois plus intelligente](https://zilliz.com/blog/How-we-used-semantic-search-to-make-our-search-10-x-smarter/)
- [Stanford AI Blog : Construction de modÃ¨les NLP Ã©volutifs, explicables et adaptatifs avec la rÃ©cupÃ©ration](https://ai.stanford.edu/blog/retrieval-based-NLP/)
- [Construction d'un moteur de recherche sÃ©mantique avec des plongements de mots Ã  double espace](https://m.mage.ai/building-a-semantic-search-engine-with-dual-space-word-embeddings-f5a596eb6d90)
- [Recherche de similaritÃ© sÃ©mantique Ã  l'Ã©chelle du milliard avec FAISS+SBERT](https://towardsdatascience.com/billion-scale-semantic-similarity-search-with-faiss-sbert-c845614962e2)
- [Quelques observations sur les seuils de recherche de similaritÃ©](https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/26/similarity-threshold-observations1.html)
- [Recherche d'images quasi identiques avec Locality Sensitive Hashing](https://keras.io/examples/vision/near_dup_search/)
- [Cours gratuit sur la recherche de similaritÃ© vectorielle et Faiss](https://link.medium.com/HtFoFKlKvkb)
- [Guide complet des algorithmes de recherche des voisins les plus proches approximatifs](https://link.medium.com/V62Z8drvEkb)
- [Introduction de l'index hybride pour permettre la recherche sÃ©mantique consciente des mots-clÃ©s](https://www.pinecone.io/learn/hybrid-search/?utm_medium=email&_hsmi=0&_hsenc=p2ANqtz--zLu9hiyh-y_XTa7FCEpi8JESJKmif5dhpYtAxTWka8PIttaTOGE21LMZlg9EOZyPYpCm6GDvYy57tlGRwH6TjgLCsJg&utm_content=231741722&utm_source=hs_email)
- [Recherche sÃ©mantique Argilla](https://docs.argilla.io/en/latest/guides/features/semantic-search.html)
- [ModÃ¨le de comprÃ©hension textuelle multilingue de Co:here](https://txt.cohere.ai/multilingual/)
- [Simplifiez la recherche avec des modÃ¨les d'embedding multilingues](https://blog.vespa.ai/simplify-search-with-multilingual-embeddings/)

## BibliothÃ¨ques et Outils
- [fastText](https://fasttext.cc/)
- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/4)
- [SBERT](https://www.sbert.net/)
- [ELECTRA](https://github.com/google-research/electra)
- [LaBSE](https://tfhub.dev/google/LaBSE/2)
- [LASER](https://github.com/facebookresearch/LASER)
- [Relevance AI - Plateforme vectorielle de l'expÃ©rimentation au dÃ©ploiement](https://relevance.ai)
- [Haystack](https://github.com/deepset-ai/haystack/)
- [Jina.AI](https://jina.ai/)
- [Pinecone](https://www.pinecone.io/)
- [SentEval Toolkit](https://github.com/facebookresearch/SentEval?utm_source=catalyzex.com)
- [ranx](https://github.com/AmenRa/ranx)
- [BEIR :Evaluation des IR](https://github.com/UKPLab/beir)
- [RELiC: Jeu de donnÃ©es de rÃ©cupÃ©ration d'Ã©lÃ©ments pour les revendications littÃ©raires](https://relic.cs.umass.edu/)
- [matchzoo-py](https://github.com/NTMC-Community/MatchZoo-py)
- [deep_text_matching](https://github.com/wangle1218/deep_text_matching)
- [Quel cadre ?](http://whichframe.com/)
- [lexica.art](https://lexica.art/)
- [Recherche sÃ©mantique emoji](https://github.com/lilianweng/emoji-semantic-search)
- [PySerini](https://github.com/castorini/pyserini)
- [BERTSerini](https://github.com/rsvp-ai/bertserini)
- [BERTSimilarity](https://github.com/Brokenwind/BertSimilarity)
- [milvus](https://www.milvus.io/)
- [NeuroNLP++](https://plusplus.neuronlp.fruitflybrain.org/)
- [weaviate](https://github.com/semi-technologies/weaviate)
- [Recherche sÃ©mantique Ã  travers Wikipedia avec Weaviate](https://github.com/semi-technologies/semantic-search-through-wikipedia-with-weaviate)
- [Recherche naturelle sur YouTube](https://github.com/haltakov/natural-language-youtube-search)
- [same.energy](https://www.same.energy/about)
- [Benchmarks ANN](http://ann-benchmarks.com/)
- [scaNN](https://github.com/google-research/google-research/tree/master/scann)
- [REALM](https://github.com/google-research/language/tree/master/language/realm)
- [annoy](https://github.com/spotify/annoy)
- [pynndescent](https://github.com/lmcinnes/pynndescent)
- [nsg](https://github.com/ZJULearning/nsg)
- [FALCONN](https://github.com/FALCONN-LIB/FALCONN)
- [redis HNSW](https://github.com/zhao-lang/redis_hnsw)
- [autofaiss](https://github.com/criteo/autofaiss)
- [DPR](https://github.com/facebookresearch/DPR)
- [rank_BM25](https://github.com/dorianbrown/rank_bm25)
- [nearPy](http://pixelogik.github.io/NearPy/)
- [vearch](https://github.com/vearch/vearch)
- [vespa](https://github.com/vespa-engine/vespa)
- [PyNNDescent](https://github.com/lmcinnes/pynndescent)
- [pgANN](https://github.com/netrasys/pgANN)
- [Tensorflow Similarity](https://github.com/tensorflow/similarity)
- [opensemanticsearch.org](https://www.opensemanticsearch.org/)
- [GPT3 Semantic Search](https://gpt3demo.com/category/semantic-search)
- [searchy](https://github.com/lubianat/searchy)
- [txtai](https://github.com/neuml/txtai)
- [HyperTag](https://github.com/Ravn-Tech/HyperTag)
- [vectorai](https://github.com/vector-ai/vectorai)
- [embeddinghub](https://github.com/featureform/embeddinghub)
- [AquilaDb](https://github.com/Aquila-Network/AquilaDB)
- [STripNet](https://github.com/stephenleo/stripnet)

## Ensembles-de-donnÃ©es
- [Semantic Text Similarity Dataset Hub](https://github.com/brmson/dataset-sts)
- [Facebook AI Image Similarity Challenge](https://www.drivendata.org/competitions/79/competition-image-similarity-1-dev/?fbclid=IwAR31vRV0EdxRdrxtPy12neZtBJQ0H9qdLHm8Wl2DjHY09PtQdn1nEEIJVUo)
- [WIT : Wikipedia-based Image Text Dataset](https://github.com/google-research-datasets/wit)
- [BEIR](https://github.com/beir-cellar/beir)
- MTEB

## Ã‰tapes Importantes

Consultez le [tableau du projet](https://github.com/Agrover112/awesome-semantic-search/projects/1) pour la liste des tÃ¢ches afin de contribuer Ã  l'une des issues ouvertes.

