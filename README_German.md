# Beeindruckende Semantische Suche [![Beeindruckend](https://awesome.re/badge.svg)](https://awesome.re) [![Konventionelle Commits](https://img.shields.io/badge/Konventionelle%20Commits-1.0.0-gelb.svg)](https://conventionalcommits.org)

![Logo](logo.svg)

Logo erstellt von [@createdbytango](https://instagram.com/createdbytango).

**Auf der Suche nach weiteren Paper-ErgÃ¤nzungen.
Hinweis: Pull Request erstellen**

Das folgende Repository soll als Meta-Repository fÃ¼r Aufgaben im Zusammenhang mit der [Semantischen Suche](https://de.wikipedia.org/wiki/Semantische_Suche) und [Semantischer Ã„hnlichkeit](http://nlpprogress.com/english/semantic_textual_similarity.html) dienen.

Semantische Suche ist nicht auf Text beschrÃ¤nkt! Sie kann mit Bildern, Sprache usw. durchgefÃ¼hrt werden. Es gibt zahlreiche unterschiedliche AnwendungsfÃ¤lle und Anwendungen der semantischen Suche.

FÃ¼hlen Sie sich frei, ein Pull Request in diesem Repository zu erstellen!

## Inhalte

- [Papers](#papers)
    - [2014](#2014)
    - [2015](#2015)
    - [2016](#2016)
    - [2017](#2017)
    - [2018](#2018)
    - [2019](#2019)
    - [2020](#2020)
    - [2021](#2021)
    - [2022](#2022)
    - [2023](#2023)
- [Artikel](#artikel)
- [Bibliotheken und Tools](#bibliotheken-und-tools)
- [DatensÃ¤tze](#datensÃ¤tze)
- [Meilensteine](#meilensteine)

## Papers

### 2010
- [PrioritÃ¤tsbereichsbÃ¤ume](https://arxiv.org/abs/1009.3527)
- [Information Retrieval und das semantische Web](https://ieeexplore.ieee.org/document/5607549) ğŸ“„

### 2014
- [Ein latentes semantisches Modell mit Convolutional-Pooling-Struktur fÃ¼r Information Retrieval](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2014_cdssm_final.pdf) ğŸ“„

### 2015
- [Ãœberspringen von Gedankenvektoren](https://arxiv.org/pdf/1506.06726.pdf) ğŸ“„
- [Praktische und optimale LSH fÃ¼r den Winkelabstand](https://proceedings.neurips.cc/paper/2015/hash/2823f4797102ce1a1aec05359cc16dd9-Abstract.html)

### 2016
- [Tricks fÃ¼r die effiziente Textklassifikation](https://arxiv.org/abs/1607.01759) ğŸ“„
- [Anreichern von Wortvektoren mit Subwortinformationen](https://arxiv.org/abs/1607.04606) ğŸ“„
- [Effiziente und robuste ungefÃ¤hre Suche nach dem nÃ¤chsten Nachbarn mit hierarchischen navigierbaren Small-World-Graphen](https://arxiv.org/abs/1603.09320)
- [UngefÃ¤hre Suche nach Ã¤hnlichen Wortvektoren](https://www.aclweb.org/anthology/P16-1214.pdf)
- [Lernen verteilter ReprÃ¤sentationen von SÃ¤tzen aus unbeschrifteten Daten](https://arxiv.org/abs/1602.03483) ğŸ“„
- [UngefÃ¤hre Suche nach dem nÃ¤chsten Nachbarn in hochdimensionalen Daten - Experimente, Analysen und Verbesserungen](https://arxiv.org/abs/1610.02455)

### 2017
- [Ãœberwachtes Lernen universeller SatzreprÃ¤sentationen aus Daten zur natÃ¼rlichen Sprachinferenz](https://research.fb.com/wp-content/uploads/2017/09/emnlp2017.pdf) ğŸ“„
- [Semantische TextÃ¤hnlichkeit fÃ¼r Hindi](https://www.semanticscholar.org/paper/Semantic-Textual-Similarity-For-Hindi-Mujadia-Mamidi/372f615ce36d7543512b8e40d6de51d17f316e0b) ğŸ“„
- [Effiziente natÃ¼rliche SprachantwortvorschlÃ¤ge fÃ¼r Smart Reply](https://arxiv.org/abs/1705.00652) ğŸ“ƒ

### 2018
- [Universal Sentence Encoder](https://arxiv.org/pdf/1803.11175.pdf) ğŸ“„
- [Lernen der semantischen TextÃ¤hnlichkeit aus GesprÃ¤chen](https://arxiv.org/pdf/1804.07754.pdf) ğŸ“„
- [Google AI Blog: Fortschritte bei der semantischen TextÃ¤hnlichkeit](https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html) ğŸ“„
- [Speech2Vec: Ein Sequenz-zu-Sequenz-Framework zur Generierung von Wortvektoren aus Sprache](https://arxiv.org/abs/1803.08976))ğŸ”Š
- [Optimierung der Indexierung auf der Grundlage des k-nÃ¤chsten Nachbarn-Graphen fÃ¼r die NÃ¤hesuche in hochdimensionalen Daten](https://arxiv.org/abs/1810.07355) ğŸ”Š
- [Schnelle ungefÃ¤hre Suche nach dem nÃ¤chsten Nachbarn mit dem Navigating Spreading-out-Graph](http://www.vldb.org/pvldb/vol12/p461-fu.pdf)
- [Der Fall fÃ¼r gelernte Indexstrukturen](https://dl.acm.org/doi/10.1145/3183713.3196909)

### 2019
- [LASER: Sprachagnostische SatzreprÃ¤sentationen](https://engineering.fb.com/2019/01/22/ai-research/laser-multilingual-sentence-embeddings/) ğŸ“„
- [Dokumenterweiterung durch Abfragevorhersage](https://arxiv.org/abs/1904.08375) ğŸ“„
- [Sentence-BERT: SatzreprÃ¤sentationen mit siamesischen BERT-Netzwerken](https://arxiv.org/pdf/1908.10084.pdf) ğŸ“„
- [Mehrstufiges Dokumentenranking mit BERT](https://arxiv.org/abs/1910.14424) ğŸ“„
- [Latente Informationssuche fÃ¼r schwach Ã¼berwachte Open-Domain-Fragenbeantwortung](https://arxiv.org/abs/1906.00300)
- [End-to-End Open-Domain-Fragenbeantwortung mit BERTserini](https://www.aclweb.org/anthology/N19-4013/)
- [BioBERT: Ein vorab trainiertes biomedizinisches SprachreprÃ¤sentationsmodell fÃ¼r die Textverarbeitung in der Biomedizin](https://arxiv.org/abs/1901.08746) ğŸ“„
- [Analyse und Verbesserung von ReprÃ¤sentationen mit dem Soft Nearest Neighbor Loss](https://arxiv.org/pdf/1902.01889.pdf) ğŸ“·
- [DiskANN: Schnelle und genaue Suche nach Milliarden von nÃ¤chsten Nachbarn auf einem einzelnen Knoten](https://proceedings.neurips.cc/paper/2019/file/09853c7fb1d3f8ee67a61b6bf4a7f8e6-Paper.pdf)

### 2020
- [Schnelle Bereitstellung einer neuronalen Suchmaschine fÃ¼r den COVID-19 Open Research-Datensatz: VorlÃ¤ufige Gedanken und gemachte Erfahrungen](https://arxiv.org/abs/2004.05125) ğŸ“„
- [Passagere-Rangfolge mit BERT](https://arxiv.org/pdf/1901.04085.pdf) ğŸ“„
- [CO-Search: COVID-19 Information Retrieval mit semantischer Suche, Frageantwort und abstrakter Zusammenfassung](https://arxiv.org/pdf/2006.09595.pdf) ğŸ“„
- [LaBSE: Sprachagnostische BERT-SatzreprÃ¤sentation](https://arxiv.org/abs/2007.01852) ğŸ“„
- [Covidex: Neuronale Rankingmodelle und SchlÃ¼sselwortsuchinfrastruktur fÃ¼r den COVID-19 Open Research-Datensatz](https://arxiv.org/abs/2007.07846) ğŸ“„
- [DeText: Ein tiefes NLP-Framework fÃ¼r intelligentes TextverstÃ¤ndnis](https://engineering.linkedin.com/blog/2020/open-sourcing-detext) ğŸ“„
- [Herstellung mehrsprachiger SatzreprÃ¤sentationen fÃ¼r Textranking: BERT und darÃ¼ber hinaus](https://arxiv.org/abs/2010.06467) ğŸ“„
- [REALM: Pre-Training von sprachmodellen mit UnterstÃ¼tzung der Informationssuche](https://arxiv.org/abs/2002.08909)
- [ELECTRA: Vorabtraining von Textcodierern als Diskriminator statt als Generator](https://openreview.net/pdf?id=r1xMH1BtvB) ğŸ“„
- [Verbesserung des Deep Learning fÃ¼r die Airbnb-Suche](https://arxiv.org/pdf/2002.05515)
- [Verwaltung der Vielfalt in der Airbnb-Suche](https://arxiv.org/abs/2004.02621) ğŸ“„
- [Negative kontrastive Lernweise fÃ¼r die ungefÃ¤hre Suche nach dem nÃ¤chsten Nachbarn mit dichten Texten](https://arxiv.org/abs/2007.00808v1) ğŸ“„
- [UnÃ¼berwachte Bildstil-Einbettungen fÃ¼r Such- und Erkennungsaufgaben](https://openaccess.thecvf.com/content_WACV_2020/papers/Gairola_Unsupervised_Image_Style_Embeddings_for_Retrieval_and_Recognition_Tasks_WACV_2020_paper.pdf) ğŸ“·
- [DeCLUTR: Tiefes kontrastives Lernen fÃ¼r unÃ¼berwachte textuelle ReprÃ¤sentationen](https://arxiv.org/abs/2006.03659) ğŸ“„

### 2021
- [Hybridansatz zur Berechnung der semantischen Ã„hnlichkeit zwischen Tamil-WÃ¶rtern](https://www.researchgate.net/publication/350112163_Hybrid_approach_for_semantic_similarity_calculation_between_Tamil_words) ğŸ“„
- [Augmented SBERT](https://arxiv.org/pdf/2010.08240.pdf) ğŸ“„
- [BEIR: Ein heterogener Benchmark zur Null-Fehler-Bewertung von Information Retrieval-Modellen](https://arxiv.org/abs/2104.08663) ğŸ“„
- [KompatibilitÃ¤tsbewusste heterogene visuelle Suche](https://arxiv.org/abs/2105.06047) ğŸ“·
- [Lernen des persÃ¶nlichen Stils aus wenigen Beispielen](https://chuanenlin.com/personalstyle) ğŸ“·
- [TSDAE: Verwendung von Transformer-basierten sequenziellen Denoising Auto-Encoder fÃ¼r das unÃ¼berwachte Erlernen von Satz-Einbettungen](https://arxiv.org/abs/2104.06979) ğŸ“„
- [Eine Umfrage Ã¼ber Transformer](https://arxiv.org/abs/2106.04554) ğŸ“„ ğŸ“·
- [SPLADE: Sparse Lexical and Expansion Model fÃ¼r das Ranking in der ersten Stufe](https://dl.acm.org/doi/10.1145/3404835.3463098) ğŸ“„
- [Hochwertige verwandte Suchanfragen mit Hilfe von Deep Reinforcement Learning](https://arxiv.org/abs/2108.04452v1)
- [Einbetten-basierte Produkt-RÃ¼ckgewinnung in der Taobao-Suche](https://arxiv.org/pdf/2106.09297.pdf) ğŸ“„ ğŸ“·
- [TPRM: Ein auf Themen basierendes personalisiertes Rangmodell fÃ¼r die Websuche](https://arxiv.org/abs/2108.06014) ğŸ“„
- [mMARCO: Eine mehrsprachige Version des MS MARCO-Passage-Ranking-Datensatzes](https://arxiv.org/abs/2108.13897) ğŸ“„
- [DatenbankbegrÃ¼ndung Ã¼ber Text](https://aclanthology.org/2021.acl-long.241.pdf) ğŸ“„
- [Wie profitiert BERT vom adversen Feintuning?](https://arxiv.org/abs/2108.13602)) ğŸ“„
- [Kurz trainieren, lange testen: Aufmerksamkeit mit linearen Verzerrungen ermÃ¶glicht die Extrapolation der EingabelÃ¤nge](https://arxiv.org/abs/2108.12409) ğŸ“„
- [Primer: Suche nach effizienten Transformator-Modellen fÃ¼r die Sprachmodellierung](https://arxiv.org/abs/2109.08668) ğŸ“„
- [Wie vertraut klingt das? Kreuz-linguale ReprÃ¤sentationsÃ¤hnlichkeitsanalyse akustischer Wort-Einbettungen](https://arxiv.org/pdf/2109.10179.pdf) ğŸ”Š
- [SimCSE: Einfaches kontrastives Lernen von Satz-Einbettungen](https://arxiv.org/abs/2104.08821#) ğŸ“„
- [Kompositionelle Aufmerksamkeit: Trennung von Suche und Abruf](https://arxiv.org/abs/2110.09419) ğŸ“„ ğŸ“·
- [SPANN: Hoch effiziente Suche nach Milliarden von ungefÃ¤hren nÃ¤chsten Nachbarn](https://arxiv.org/abs/2111.08566)
- [GPL: Generatives Pseudo Labeling fÃ¼r das unÃ¼berwachte Domain-Adaptation von dichter Suche](https://arxiv.org/abs/2112.07577) ğŸ“„
- [Generative Suchmaschinen: Erste Experimente](https://computationalcreativity.net/iccc21/wp-content/uploads/2021/09/ICCC_2021_paper_50.pdf) ğŸ“·
- [Neubewertung der Suche: Aus Dilettanten werden Experten](https://dl.acm.org/doi/10.1145/3476415.3476428)
- [WhiteningBERT: Ein einfacher unÃ¼berwachter Ansatz zur Satz-Einbettung](https://arxiv.org/abs/2104.01767)

### 2022
- [Text- und Code-Einbettungen durch kontrastives Vorabtraining](https://arxiv.org/abs/2201.10005) ğŸ“„
- [RELIC: Retrieving Evidence for Literary Claims](https://arxiv.org/abs/2203.10053) ğŸ“„
- [Trans-Encoder: UnÃ¼berwachte Modellierung von Satzpaaren durch Selbst- und gegenseitige Abmilderung](https://arxiv.org/abs/2109.13059) ğŸ“„
- [SAMU-XLSR: Semantisch ausgerichtete mehrsprachige Ã„uÃŸerungslevel-Kreuz-linguale SprachreprÃ¤sentation](https://arxiv.org/abs/2205.08180) ğŸ”Š
- [Eine Analyse von Verschmelzungsfunktionen fÃ¼r die hybride Suche](https://arxiv.org/abs/2210.11934) ğŸ“„
- [Out-of-Distribution Detection mit Deep Nearest Neighbors](https://arxiv.org/abs/2204.06507)
- [ESB: Ein Benchmark fÃ¼r Multi-Domain End-to-End-Spracherkennung](https://arxiv.org/abs/2210.13352) ğŸ”Š
- [Analyse von akustischen Wort-Einbettungen aus vorab trainierten selbstÃ¼berwachten Sprachmodellen](https://arxiv.org/pdf/2210.16043.pdf)) ğŸ”Š
- [Rethinking with Retrieval: Faithful Large Language Model Inference](https://arxiv.org/abs/2301.00303) ğŸ“„
- [PrÃ¤zise Null-Fehler dichte Suche ohne Relevanzetiketten](https://arxiv.org/pdf/2212.10496.pdf) ğŸ“„
- [Transformer-Speicher als ein differenzierbarer Suchindex](https://arxiv.org/abs/2202.06991) ğŸ“„

### 2023
- [FINGER: Schnelle Inferenz fÃ¼r graphenbasierte ungefÃ¤hre Suche nach den nÃ¤chsten Nachbarn](https://dl.acm.org/doi/10.1145/3543507.3583318) ğŸ“„
- ["Low-Resource" Textklassifikation: Eine parameterfreie Klassifikationsmethode mit Kompressoren](https://aclanthology.org/2023.findings-acl.426/) ğŸ“„
- [SparseEmbed: Lernen von dÃ¼nnen lexikalischen ReprÃ¤sentationen mit kontextuellen Einbettungen fÃ¼r die Suche](https://dl.acm.org/doi/pdf/10.1145/3539618.3592065) ğŸ“„

## Artikel
- [Semantic Search in Azure Cognitive Search](https://docs.microsoft.com/en-us/azure/search/semantic-search-overview) (Semantische Suche in Azure Cognitive Search)
- [So haben wir die semantische Suche verwendet, um unsere Suche um das 10-fache intelligenter zu machen](https://zilliz.com/blog/How-we-used-semantic-search-to-make-our-search-10-x-smarter/) (Englisch)
- [Stanford AI Blog: Aufbau von skalierbaren, erklÃ¤rbaren und anpassbaren NLP-Modellen mit Retrieval](https://ai.stanford.edu/blog/retrieval-based-NLP/) (Englisch)
- [Aufbau einer semantischen Suchmaschine mit Dual-Space-Wort-Einbettungen](https://m.mage.ai/building-a-semantic-search-engine-with-dual-space-word-embeddings-f5a596eb6d90) (Englisch)
- [Milliardenskala semantische Ã„hnlichkeitssuche mit FAISS+SBERT](https://towardsdatascience.com/billion-scale-semantic-similarity-search-with-faiss-sbert-c845614962e2) (Englisch)
- [Einige Beobachtungen zu Schwellenwerten fÃ¼r die Ã„hnlichkeitssuche](https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/26/similarity-threshold-observations1.html) (Englisch)
- [Suche nach Ã¤hnlichen Bildern mit lokalitÃ¤tssensitivem Hashing](https://keras.io/examples/vision/similarity_search/) (Englisch)
- [EinfÃ¼hrung in die semantische Suche mit TensorFlow](https://blog.tensorflow.org/2019/07/introducing-semantic-search-with.html) (Englisch)

## Bibliotheken und Tools
- [HNSW](https://github.com/nmslib/hnswlib): Hierarchisches Navigieren in Small-World-Graphen (HNSW) - eine Bibliothek zur Erstellung von Indexen fÃ¼r die nÃ¤chste Nachbarschaftssuche.
- [FAISS](https://github.com/facebookresearch/faiss): Bibliothek zur schnellen AnnÃ¤herung an die nÃ¤chste Nachbarschaftssuche.
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers): Eine Sammlung von vortrainierten Modellen zur Erstellung von Satzvektoren.
- [Dense Retrieval](https://github.com/ibayer/dense-retrieval): Bibliothek und Tools zur Implementierung von Dense Retrieval-Modellen.
- [ANN-Benchmarks](https://github.com/erikbern/ann-benchmarks): Eine Sammlung von Benchmarks fÃ¼r Approximate Nearest Neighbor (ANN)-Bibliotheken.

## DatensÃ¤tze
- [MS MARCO](https://microsoft.github.io/msmarco/): Ein umfangreicher Datensatz zur Informationssuche, der fÃ¼r verschiedene Aufgaben verwendet werden kann.
- [COVID-19 Open Research-Datensatz (CORD-19)](https://www.semanticscholar.org/cord19): Ein Datensatz mit wissenschaftlichen Artikeln zur COVID-19-Forschung.
- [Kaggle - Jigsaw Multilingual Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification): Ein Datensatz zur Klassifikation von toxischen Kommentaren in verschiedenen Sprachen.
- [BioASQ](http://bioasq.org/): Ein Datensatz zur Biomedizinischen Informationssuche.
- [Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions): Ein Datensatz fÃ¼r die natÃ¼rliche Fragenbeantwortung und Informationssuche.

## Meilensteine
- 2019: LASER, Sentence-BERT
- 2020: TREC-COVID, COVID-19-Open Research-Datensatz (CORD-19)
- 2021: BEIR-Benchmark, mMARCO, REALM, Transformers mit Linearschicht-Verzerrungen
- 2022: Text- und Code-Einbettungen, SAMU-XLSR, DeText, Trans-Encoder
- 2023: FINGER, ESB-Benchmark

## Andere Awesome-Listen
- [Awesome](https://github.com/sindresorhus/awesome): Ein zentrales Repository fÃ¼r Awesome-Listen, auf dem Sie Listen zu vielen anderen Themen finden kÃ¶nnen.
- [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning): Eine groÃŸe Sammlung von Ressourcen und Tools im Bereich Machine Learning.
- [Awesome NLP](https://github.com/keon/awesome-nlp): Eine Liste mit Ressourcen und Tools im Bereich der Natural Language Processing.
- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience): Eine Zusammenstellung von Tools und Ressourcen fÃ¼r Data Science und Machine Learning.
- [Awesome Semantic Web](https://github.com/semantalytics/awesome-semantic-web): Eine Sammlung von Ressourcen im Bereich des Semantischen Webs.

**Hinweis:** Diese Liste wird regelmÃ¤ÃŸig aktualisiert, um die neuesten Entwicklungen im Bereich der semantischen Suche und semantischen Ã„hnlichkeit widerzuspiegeln. Wenn Sie VorschlÃ¤ge fÃ¼r ErgÃ¤nzungen haben, kÃ¶nnen Sie gerne ein Pull Request erstellen.
